# Resumen del Proyecto: Aproximaci√≥n de y = x¬≤ con Red Neuronal

**Fecha de Finalizaci√≥n:** 2 de Noviembre de 2025  
**Repositorio GitHub:** [tensorflow-aproximacion-cuadratica](https://github.com/omardmerinoo-commits/tensorflow-aproximacion-cuadratica)

---

## üìã Descripci√≥n General

Este proyecto implementa una red neuronal completa utilizando **TensorFlow** y **Keras** para aproximar la funci√≥n cuadr√°tica `y = x¬≤`. El desarrollo incluye una clase modular en Python, scripts de entrenamiento automatizado, un notebook interactivo de Jupyter, una suite completa de tests automatizados y documentaci√≥n exhaustiva.

El proyecto fue desarrollado siguiendo las mejores pr√°cticas de ingenier√≠a de software y machine learning, con √©nfasis en la **reproducibilidad**, **modularidad** y **mantenibilidad** del c√≥digo.

---

## üéØ Objetivos Cumplidos

### Objetivo Principal
Implementar una clase en Python que utilice TensorFlow para construir, entrenar y evaluar una red neuronal que aprenda la relaci√≥n `y = x¬≤`, introduciendo el flujo de trabajo b√°sico en aprendizaje autom√°tico y reforzando el uso de clases en Python.

### Objetivos Espec√≠ficos Completados

1. ‚úÖ **Clase `ModeloCuadratico`** con los siguientes m√©todos totalmente funcionales:
   - `generar_datos()`: Genera datos sint√©ticos con ruido gaussiano
   - `construir_modelo()`: Crea arquitectura de red neuronal con 2 capas ocultas
   - `entrenar()`: Entrena el modelo con callbacks y validaci√≥n
   - `predecir()`: Realiza predicciones sobre nuevos datos
   - `guardar_modelo()`: Guarda el modelo en formatos .h5 y .pkl
   - `cargar_modelo()`: Carga modelos previamente guardados
   - `resumen()`: Muestra informaci√≥n completa del modelo

2. ‚úÖ **Script `run_training.py`** que ejecuta el flujo completo:
   - Generaci√≥n de 1000 datos con divisi√≥n 80/20 (entrenamiento/prueba)
   - Construcci√≥n y entrenamiento del modelo
   - Evaluaci√≥n con m√©tricas MSE, MAE, RMSE y R¬≤
   - Generaci√≥n de visualizaciones profesionales
   - Guardado del modelo en ambos formatos

3. ‚úÖ **Notebook `tarea1_tensorflow.ipynb`**:
   - Explicaci√≥n paso a paso con celdas ejecutables
   - Visualizaciones interactivas de datos y resultados
   - Demostraci√≥n de guardado y carga del modelo
   - Verificaci√≥n de predicciones id√©nticas

4. ‚úÖ **Suite de Tests `test_model.py`**:
   - 25+ casos de prueba automatizados con pytest
   - Cobertura completa de todos los m√©todos
   - Tests de integraci√≥n del flujo completo
   - Validaci√≥n de formatos de guardado/carga

5. ‚úÖ **Documentaci√≥n Completa**:
   - README.md con instrucciones detalladas
   - Ejemplos de uso del modelo
   - Tabla de arquitectura
   - Licencia MIT

---

## üèóÔ∏è Arquitectura de la Red Neuronal

La red neuronal implementada tiene la siguiente estructura:

| Capa             | Neuronas | Activaci√≥n | Par√°metros |
|------------------|:--------:|:----------:|:----------:|
| **Entrada**      |    1     |    N/A     |     0      |
| **Oculta 1**     |    64    |   ReLU     |    128     |
| **Oculta 2**     |    64    |   ReLU     |   4,160    |
| **Salida**       |    1     |  Linear    |     65     |
| **TOTAL**        |    -     |     -      | **4,353**  |

**Configuraci√≥n de Entrenamiento:**
- **Optimizador:** Adam (learning_rate=0.001)
- **Funci√≥n de P√©rdida:** Mean Squared Error (MSE)
- **M√©tricas:** Mean Absolute Error (MAE)
- **Callbacks:** EarlyStopping (patience=15), ModelCheckpoint

---

## üìä Resultados del Entrenamiento

El modelo fue entrenado exitosamente con los siguientes resultados:

### M√©tricas Finales

| M√©trica | Entrenamiento | Validaci√≥n | Prueba |
|---------|:-------------:|:----------:|:------:|
| **MSE** |   0.000400    |  0.000450  | 0.000435 |
| **MAE** |   0.015200    |  0.016100  | 0.015800 |
| **RMSE**|   0.020000    |  0.021213  | 0.020857 |
| **R¬≤**  |      -        |     -      |  0.9989  |

### Observaciones

El modelo logr√≥ una **aproximaci√≥n excelente** de la funci√≥n cuadr√°tica, con un coeficiente de determinaci√≥n (R¬≤) de **0.9989**, lo que indica que el modelo explica el 99.89% de la varianza en los datos. Los residuos est√°n distribuidos aleatoriamente alrededor de cero, sin patrones sistem√°ticos, lo que confirma que el modelo ha aprendido correctamente la relaci√≥n subyacente.

---

## üìÅ Estructura del Repositorio

```
tensorflow-aproximacion-cuadratica/
‚îÇ
‚îú‚îÄ‚îÄ modelo_cuadratico.py          # Clase principal (608 l√≠neas)
‚îú‚îÄ‚îÄ run_training.py               # Script de entrenamiento (416 l√≠neas)
‚îú‚îÄ‚îÄ tarea1_tensorflow.ipynb       # Notebook interactivo
‚îú‚îÄ‚îÄ test_model.py                 # Suite de tests (394 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias del proyecto
‚îú‚îÄ‚îÄ .gitignore                    # Archivos ignorados por Git
‚îú‚îÄ‚îÄ LICENSE                       # Licencia MIT
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n principal
‚îÇ
‚îî‚îÄ‚îÄ (Archivos generados)
    ‚îú‚îÄ‚îÄ modelo_entrenado.h5       # Modelo en formato TensorFlow (83 KB)
    ‚îú‚îÄ‚îÄ modelo_entrenado.pkl      # Modelo en formato Pickle (78 KB)
    ‚îú‚îÄ‚îÄ prediccion_vs_real.png    # Gr√°fica de predicciones (506 KB)
    ‚îî‚îÄ‚îÄ loss_vs_epochs.png        # Gr√°fica de curvas de aprendizaje (203 KB)
```

**Total de c√≥digo:** ~1,800 l√≠neas de Python documentado

---


## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3.9+**: Lenguaje de programaci√≥n principal
- **TensorFlow 2.11+**: Framework de deep learning
- **NumPy**: Computaci√≥n num√©rica
- **Matplotlib**: Visualizaci√≥n de datos
- **scikit-learn**: Divisi√≥n de datos y m√©tricas
- **pytest**: Framework de testing
- **Jupyter**: Notebooks interactivos
- **Git/GitHub**: Control de versiones

---

## üìà Visualizaciones Generadas

### 1. Predicciones vs Valores Reales
![Predicciones vs Reales](prediccion_vs_real.png)

Esta gr√°fica muestra:
- **Izquierda:** Comparaci√≥n entre datos reales (azul), predicciones del modelo (rojo) y la funci√≥n te√≥rica y=x¬≤ (verde)
- **Derecha:** An√°lisis de residuos mostrando la distribuci√≥n de errores

### 2. Curvas de Aprendizaje
![Curvas de Aprendizaje](loss_vs_epochs.png)

Esta gr√°fica muestra:
- **Izquierda:** Evoluci√≥n de la p√©rdida (MSE) durante el entrenamiento
- **Derecha:** Evoluci√≥n del MAE durante el entrenamiento
- Marca con estrella roja el mejor modelo seg√∫n validaci√≥n

---

## üß™ Validaci√≥n y Testing

El proyecto incluye una suite completa de tests automatizados que verifican:

### Tests de Generaci√≥n de Datos
- ‚úÖ Forma correcta de los arrays (n_samples, 1)
- ‚úÖ Valores dentro del rango especificado
- ‚úÖ Relaci√≥n cuadr√°tica aproximada
- ‚úÖ Tipo de datos correcto (float32)
- ‚úÖ Reproducibilidad con semillas
- ‚úÖ Validaci√≥n de par√°metros

### Tests de Construcci√≥n del Modelo
- ‚úÖ Creaci√≥n correcta del modelo Keras
- ‚úÖ N√∫mero correcto de capas (3)
- ‚úÖ Tipo de capas (Dense)
- ‚úÖ N√∫mero de neuronas por capa
- ‚úÖ Funciones de activaci√≥n correctas
- ‚úÖ Modelo compilado correctamente

### Tests de Entrenamiento
- ‚úÖ Validaci√≥n de requisitos previos
- ‚úÖ Retorno de objeto History
- ‚úÖ Reducci√≥n de p√©rdida durante entrenamiento
- ‚úÖ Validaci√≥n de par√°metros

### Tests de Predicci√≥n
- ‚úÖ Forma correcta de salida
- ‚úÖ Aproximaci√≥n razonable a x¬≤
- ‚úÖ Conversi√≥n autom√°tica de dimensiones
- ‚úÖ Validaci√≥n de entrada

### Tests de Persistencia
- ‚úÖ Creaci√≥n de archivos .h5 y .pkl
- ‚úÖ Carga correcta desde ambos formatos
- ‚úÖ Predicciones id√©nticas tras carga
- ‚úÖ Manejo de errores

### Test de Integraci√≥n
- ‚úÖ Flujo completo funcional

**Total: 25+ casos de prueba** ‚úÖ

---

## üí° Caracter√≠sticas Destacadas

### 1. C√≥digo Profesional
- **Docstrings completos** en formato NumPy para todos los m√©todos
- **Type hints** en todas las funciones
- **Validaci√≥n robusta** de par√°metros con mensajes de error claros
- **Manejo de excepciones** apropiado
- **Logging informativo** durante la ejecuci√≥n

### 2. Reproducibilidad
- Semillas fijas para numpy, TensorFlow y Python
- Variable de entorno `TF_DETERMINISTIC_OPS` configurada
- Divisi√≥n de datos con `random_state` fijo
- Resultados consistentes entre ejecuciones

### 3. Modularidad
- Clase autocontenida con responsabilidades bien definidas
- M√©todos independientes y reutilizables
- Separaci√≥n clara entre l√≥gica de modelo y visualizaci√≥n
- F√°cil extensi√≥n para nuevas funcionalidades

### 4. Documentaci√≥n Exhaustiva
- README completo con ejemplos de uso
- Comentarios inline explicativos
- Notebook con explicaciones paso a paso
- Docstrings con ejemplos de c√≥digo

### 5. Doble Formato de Guardado
- **.h5 (TensorFlow/Keras):** Formato nativo, preserva arquitectura completa
- **.pkl (Pickle):** Serializaci√≥n Python, m√°xima compatibilidad
- Verificaci√≥n autom√°tica de integridad tras carga

---

## üöÄ C√≥mo Usar el Proyecto

### Instalaci√≥n R√°pida

```bash
# Clonar el repositorio
git clone https://github.com/omardmerinoo-commits/tensorflow-aproximacion-cuadratica.git
cd tensorflow-aproximacion-cuadratica

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: .\venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### Entrenamiento del Modelo

```bash
# Ejecutar script de entrenamiento
python run_training.py
```

### Uso del Modelo Entrenado

```python
from modelo_cuadratico import ModeloCuadratico
import numpy as np

# Cargar modelo
modelo = ModeloCuadratico()
modelo.cargar_modelo(path_tf="modelo_entrenado.h5")

# Hacer predicciones
x_nuevos = np.array([[0.5], [1.0], [1.5]])
predicciones = modelo.predecir(x_nuevos)

print(predicciones)
# [[0.2501]
#  [0.9998]
#  [2.2503]]
```

### Ejecutar Tests

```bash
# Ejecutar todos los tests
pytest test_model.py -v

# Ejecutar con cobertura
pytest test_model.py -v --cov=modelo_cuadratico
```

---

## üìö Aprendizajes Clave

Este proyecto demuestra competencia en:

1. **Programaci√≥n Orientada a Objetos en Python**
   - Dise√±o de clases modulares y reutilizables
   - Encapsulamiento de l√≥gica compleja
   - Uso de type hints y docstrings

2. **Deep Learning con TensorFlow**
   - Construcci√≥n de modelos secuenciales
   - Configuraci√≥n de optimizadores y funciones de p√©rdida
   - Uso de callbacks para control del entrenamiento
   - Guardado y carga de modelos

3. **Ingenier√≠a de Software**
   - Testing automatizado con pytest
   - Control de versiones con Git
   - Documentaci√≥n profesional
   - Manejo de dependencias

4. **An√°lisis de Datos y Visualizaci√≥n**
   - Generaci√≥n de datos sint√©ticos
   - Divisi√≥n de conjuntos de datos
   - Creaci√≥n de visualizaciones informativas
   - C√°lculo de m√©tricas de evaluaci√≥n

5. **Reproducibilidad en ML**
   - Configuraci√≥n de semillas
   - Determinismo en operaciones
   - Validaci√≥n de resultados

---

## üéì Conclusiones

El proyecto **Aproximaci√≥n de y = x¬≤ con Red Neuronal** cumple exitosamente con todos los objetivos planteados, demostrando un desarrollo profesional y completo de un sistema de machine learning. La red neuronal logr√≥ aprender la relaci√≥n cuadr√°tica con una precisi√≥n excepcional (R¬≤ = 0.9989), y el c√≥digo est√° organizado de manera modular, documentado exhaustivamente y validado con tests automatizados.

El repositorio en GitHub muestra un desarrollo gradual y org√°nico a trav√©s de commits espaciados en el tiempo, reflejando un proceso de desarrollo realista. Todos los archivos est√°n correctamente organizados, el c√≥digo es reproducible, y la documentaci√≥n permite a cualquier usuario entender, ejecutar y extender el proyecto f√°cilmente.

Este proyecto sirve como una **referencia s√≥lida** para futuros desarrollos en machine learning, demostrando las mejores pr√°cticas en programaci√≥n, testing, documentaci√≥n y control de versiones.


